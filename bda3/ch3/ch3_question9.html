<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Bayesian Derivation: Conjugate Normal Model</title>
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- KaTeX for Math Rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" xintegrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" xintegrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" xintegrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
    
    <!-- Google Fonts for Academic Look -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:ital,wght@0,400;0,600;0,700;1,400&family=Inter:wght@300;400;500;600&display=swap" rel="stylesheet">

    <style>
        body { 
            font-family: 'Inter', sans-serif; 
            background-color: #f8fafc;
        }
        h1, h2, h3, .math-serif {
            font-family: 'Crimson Pro', serif;
        }
        .step-card { 
            @apply bg-white p-8 rounded-xl shadow-sm border border-gray-200 mb-8 transition-all duration-300 hover:shadow-md; 
        }
        .math-block { 
            @apply overflow-x-auto py-4 px-2 my-2 text-lg; 
        }
        .highlight-box {
            @apply bg-slate-50 border-l-4 border-indigo-500 p-4 my-4 rounded-r-lg;
        }
        .explanation-text {
            @apply text-slate-700 leading-relaxed mb-4;
        }
        /* Custom scrollbar for math */
        .math-block::-webkit-scrollbar {
            height: 6px;
        }
        .math-block::-webkit-scrollbar-thumb {
            background-color: #cbd5e1;
            border-radius: 4px;
        }
        .home-button {
            position: fixed;
            top: 20px;
            left: 20px;
            background: #2c3e50;
            color: white;
            border: none;
            padding: 12px 20px;
            border-radius: 25px;
            font-size: 14px;
            font-weight: 500;
            cursor: pointer;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.2);
            transition: all 0.3s ease;
            z-index: 1000;
        }
        .home-button:hover {
            background: #34495e;
            transform: translateY(-2px);
            box-shadow: 0 4px 15px rgba(0,0,0,0.3);
        }
    </style>
</head>
<body class="text-slate-800 antialiased">
    <!-- Home Buttn -->
    <a href="../../index.html" class="home-button">
        ‚Üê Home
    </a>
    <div class="max-w-3xl mx-auto px-4 py-12">
        
        <!-- Header -->
        <header class="mb-12 text-center border-b border-gray-200 pb-8">
            <h1 class="text-4xl md:text-5xl font-bold text-slate-900 mt-2 mb-4">Conjugate Normal Model</h1>
            <p class="text-xl text-slate-600 font-serif italic">Step-by-Step Derivation of the Posterior Distribution</p>
        </header>

        <!-- Problem Statement (Light Gray Box) -->
        <section class="mb-12">
            <div class="bg-gray-50 border border-gray-200 p-8 rounded-lg shadow-sm relative">
                <div class="absolute top-0 left-0 bottom-0 w-1 bg-gray-400 rounded-l-lg"></div>
                <h2 class="text-2xl font-bold mb-6 text-slate-800 border-b border-gray-300 pb-3 flex items-center gap-2">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 text-slate-500" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
                    </svg>
                    Question 9
                </h2>
                <div class="space-y-4 text-slate-700 leading-relaxed font-medium">
                    <p>
                        <strong>Data:</strong> Suppose \(y\) is an independent and identically distributed (i.i.d.) sample of size \(n\) from the distribution \(N(\mu, \sigma^2)\).
                    </p>
                    <p>
                        <strong>Prior:</strong> The joint prior distribution for \((\mu, \sigma^2)\) is \(N\text{-Inv-}\chi^2(\mu, \sigma^2 | \mu_0, \sigma_0^2/\kappa_0; \nu_0, \sigma_0^2)\); that is:
                        \[ \sigma^2 \sim \text{Inv-}\chi^2(\nu_0, \sigma_0^2) \quad \text{and} \quad \mu|\sigma^2 \sim N(\mu_0, \sigma^2/\kappa_0) \]
                    </p>
                    <p>
                        <strong>Task:</strong> Derive explicitly the parameters of the posterior distribution \(p(\mu, \sigma^2|y)\) in terms of the prior parameters and the sufficient statistics of the data.
                    </p>
                </div>
            </div>
        </section>

        <!-- Derivation Steps -->
        
        <!-- Step 1 -->
        <div class="step-card group">
            <div class="flex items-center gap-3 mb-4">
                <div class="flex items-center justify-center w-8 h-8 rounded-full bg-indigo-100 text-indigo-700 font-bold font-serif">1</div>
                <h3 class="text-2xl font-semibold text-slate-900">Constructing the Likelihood Function</h3>
            </div>
            
            <p class="explanation-text">
                First, I need to establish the likelihood function for the data. Since the observations \(y_1, \dots, y_n\) are independent and identically distributed (i.i.d.) given the parameters \((\mu, \sigma^2)\), the joint likelihood is the product of the individual Normal probability density functions.
            </p>
            <p class="explanation-text">
                I will write the kernel of the likelihood, dropping multiplicative constants (like \((2\pi)^{-n/2}\)) that do not depend on the parameters \(\mu\) or \(\sigma^2\):
            </p>
            
            <div class="math-block">
                $$ \begin{aligned} 
                p(y|\mu, \sigma^2) &= \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{(y_i - \mu)^2}{2\sigma^2} \right) \\
                &\propto (\sigma^2)^{-n/2} \exp\left( -\frac{1}{2\sigma^2} \sum_{i=1}^n (y_i - \mu)^2 \right)
                \end{aligned} $$
            </div>

            <div class="highlight-box">
                <p class="text-sm font-semibold text-indigo-900 mb-2 font-serif">Justification: Simplifying the Sum of Squares</p>
                <p class="explanation-text text-sm">
                    To make the derivation manageable, I must separate the data variation from the parameter \(\mu\). I use the standard algebraic trick of adding and subtracting the sample mean \(\bar{y}\) inside the square:
                </p>
                <div class="math-block text-sm">
                    $$ \begin{aligned}
                    \sum_{i=1}^n (y_i - \mu)^2 &= \sum_{i=1}^n ((y_i - \bar{y}) + (\bar{y} - \mu))^2 \\
                    &= \sum_{i=1}^n (y_i - \bar{y})^2 + \sum_{i=1}^n (\bar{y} - \mu)^2 + 2(\bar{y} - \mu)\underbrace{\sum_{i=1}^n (y_i - \bar{y})}_{=0} \\
                    &= SSE + n(\bar{y} - \mu)^2
                    \end{aligned} $$
                </div>
                <p class="explanation-text text-sm italic">
                    Note: The cross-term vanishes because the sum of deviations from the sample mean is always zero.
                </p>
            </div>

            <p class="explanation-text">
                Substituting this expansion back into the likelihood, I obtain the simplified form:
            </p>
            <div class="math-block">
                $$ p(y|\mu, \sigma^2) \propto (\sigma^2)^{-n/2} \exp\left( -\frac{1}{2\sigma^2} \left[ SSE + n(\bar{y} - \mu)^2 \right] \right) $$
            </div>
        </div>

        <!-- Step 2 -->
        <div class="step-card">
            <div class="flex items-center gap-3 mb-4">
                <div class="flex items-center justify-center w-8 h-8 rounded-full bg-indigo-100 text-indigo-700 font-bold font-serif">2</div>
                <h3 class="text-2xl font-semibold text-slate-900">Formulating the Joint Prior</h3>
            </div>
            <p class="explanation-text">
                The problem specifies a hierarchical prior structure. I must construct the joint prior density \(p(\mu, \sigma^2)\) by multiplying the conditional density by the marginal density:
                \[ p(\mu, \sigma^2) = p(\mu|\sigma^2) \times p(\sigma^2) \]
            </p>
            
            <p class="explanation-text">
                <strong>1. Conditional Prior for \(\mu\):</strong> Given \(\mu|\sigma^2 \sim N(\mu_0, \sigma^2/\kappa_0)\), the kernel is:
            </p>
            <div class="math-block">
                $$ p(\mu|\sigma^2) \propto (\sigma^2)^{-1/2} \exp\left( -\frac{\kappa_0(\mu - \mu_0)^2}{2\sigma^2} \right) $$
            </div>

            <p class="explanation-text">
                <strong>2. Marginal Prior for \(\sigma^2\):</strong> Given \(\sigma^2 \sim \text{Inv-}\chi^2(\nu_0, \sigma_0^2)\), the kernel is:
            </p>
            <div class="math-block">
                $$ p(\sigma^2) \propto (\sigma^2)^{-(\nu_0/2 + 1)} \exp\left( -\frac{\nu_0\sigma_0^2}{2\sigma^2} \right) $$
            </div>

            <p class="explanation-text">
                <strong>3. The Joint Prior:</strong> Multiplying these together and combining the powers of \(\sigma^2\):
            </p>
            <div class="math-block">
                $$ \begin{aligned}
                p(\mu, \sigma^2) &\propto (\sigma^2)^{-1/2} (\sigma^2)^{-(\nu_0/2 + 1)} \exp\left( -\frac{1}{2\sigma^2} [\kappa_0(\mu - \mu_0)^2 + \nu_0\sigma_0^2] \right) \\
                &\propto (\sigma^2)^{-\frac{\nu_0 + 3}{2}} \exp\left( -\frac{1}{2\sigma^2} [\nu_0\sigma_0^2 + \kappa_0(\mu - \mu_0)^2] \right)
                \end{aligned} $$
            </div>
        </div>

        <!-- Step 3 -->
        <div class="step-card">
            <div class="flex items-center gap-3 mb-4">
                <div class="flex items-center justify-center w-8 h-8 rounded-full bg-indigo-100 text-indigo-700 font-bold font-serif">3</div>
                <h3 class="text-2xl font-semibold text-slate-900">Deriving the Posterior Kernel</h3>
            </div>
            <p class="explanation-text">
                I now apply Bayes' Theorem: \(\text{Posterior} \propto \text{Prior} \times \text{Likelihood}\). I will combine the terms derived in Steps 1 and 2.
            </p>

            <div class="math-block">
                $$ \begin{aligned}
                p(\mu, \sigma^2|y) &\propto \underbrace{(\sigma^2)^{-\frac{\nu_0+3}{2}} \exp\left( -\frac{\nu_0\sigma_0^2 + \kappa_0(\mu-\mu_0)^2}{2\sigma^2} \right)}_{\text{Prior}} \\
                &\quad \times \underbrace{(\sigma^2)^{-n/2} \exp\left( -\frac{SSE + n(\bar{y}-\mu)^2}{2\sigma^2} \right)}_{\text{Likelihood}}
                \end{aligned} $$
            </div>
            
            <p class="explanation-text">
                I will simplify this by adding the exponents of \(\sigma^2\) and summing the terms inside the exponential function:
            </p>
            <div class="math-block">
                $$ \begin{aligned}
                p(\mu, \sigma^2|y) &\propto (\sigma^2)^{-\frac{\nu_0 + n + 3}{2}} \\
                &\quad \times \exp\left( -\frac{1}{2\sigma^2} \Big[ (\nu_0\sigma_0^2 + SSE) + \kappa_0(\mu-\mu_0)^2 + n(\mu-\bar{y})^2 \Big] \right)
                \end{aligned} $$
            </div>
        </div>

        <!-- Step 4 -->
        <div class="step-card ring-1 ring-indigo-100">
            <div class="flex items-center gap-3 mb-4">
                <div class="flex items-center justify-center w-8 h-8 rounded-full bg-indigo-600 text-white font-bold font-serif">4</div>
                <h3 class="text-2xl font-semibold text-indigo-900">Identifying Posterior Parameters</h3>
            </div>
            <p class="explanation-text">
                This is the critical step. I need to demonstrate that the expression inside the exponential matches the form of a Normal-Inverse-\(\chi^2\) kernel. To do this, I must combine the two quadratic terms involving \(\mu\) into a single square.
            </p>
            
            <p class="explanation-text font-semibold text-indigo-800">
                Method: Completing the Square
            </p>
            <p class="explanation-text">
                I use the algebraic identity: \(A(x-a)^2 + B(x-b)^2 = (A+B)(x - \text{weighted\_avg})^2 + \text{residual}\).
            </p>
            <div class="math-block text-slate-700 text-base mb-4">
                $$ \kappa_0(\mu-\mu_0)^2 + n(\mu-\bar{y})^2 = (\kappa_0+n)\left(\mu - \frac{\kappa_0\mu_0 + n\bar{y}}{\kappa_0+n}\right)^2 + \frac{\kappa_0 n}{\kappa_0+n}(\bar{y} - \mu_0)^2 $$
            </div>

            <p class="explanation-text">
                From this expansion, I can explicitly define the new posterior parameters.
            </p>

            <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mt-6">
                <!-- Precision -->
                <div class="bg-blue-50 p-5 rounded-lg border border-blue-100">
                    <span class="text-xs font-bold text-blue-600 uppercase tracking-wide">1. Posterior Precision (\(\kappa_n\))</span>
                    <p class="text-sm text-slate-600 mt-2 mb-2">The coefficient of the squared term for \(\mu\).</p>
                    <div class="text-xl font-serif">$$ \kappa_n = \kappa_0 + n $$</div>
                </div>
                <!-- Mean -->
                <div class="bg-blue-50 p-5 rounded-lg border border-blue-100">
                    <span class="text-xs font-bold text-blue-600 uppercase tracking-wide">2. Posterior Mean (\(\mu_n\))</span>
                    <p class="text-sm text-slate-600 mt-2 mb-2">The weighted average of the prior and data means.</p>
                    <div class="text-xl font-serif">$$ \mu_n = \frac{\kappa_0\mu_0 + n\bar{y}}{\kappa_n} $$</div>
                </div>
            </div>

            <p class="explanation-text mt-8">
                Now I substitute the completed square back into the total exponent. The "constant" part (not involving \(\mu\)) becomes the new scale parameter.
            </p>

            <div class="math-block">
                $$ \text{Total Exponent Numerator} = \underbrace{\nu_0\sigma_0^2}_{\text{Prior Scale}} + \underbrace{SSE}_{\text{Data Var}} + \underbrace{\frac{\kappa_0 n}{\kappa_n}(\bar{y}-\mu_0)^2}_{\text{Mean Shift}} + \kappa_n(\mu-\mu_n)^2 $$
            </div>

            <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mt-6">
                <!-- Degrees of Freedom -->
                <div class="bg-emerald-50 p-5 rounded-lg border border-emerald-100">
                    <span class="text-xs font-bold text-emerald-600 uppercase tracking-wide">3. Posterior Degrees of Freedom (\(\nu_n\))</span>
                    <p class="text-sm text-slate-600 mt-2 mb-2">Matching the power of \((\sigma^2)^{-(\nu_n+3)/2}\).</p>
                    <div class="text-xl font-serif">$$ \nu_n = \nu_0 + n $$</div>
                </div>
                <!-- Scale Parameter -->
                <div class="bg-emerald-50 p-5 rounded-lg border border-emerald-100">
                    <span class="text-xs font-bold text-emerald-600 uppercase tracking-wide">4. Posterior Scale (\(\sigma_n^2\))</span>
                    <p class="text-sm text-slate-600 mt-2 mb-2">The sum of all variance components divided by \(\nu_n\).</p>
                    <div class="text-xl font-serif">$$ \sigma_n^2 = \frac{\nu_0\sigma_0^2 + SSE + \frac{\kappa_0 n}{\kappa_n}(\bar{y} - \mu_0)^2}{\nu_n} $$</div>
                </div>
            </div>
        </div>

        <!-- Step 5 -->
        <div class="step-card">
            <div class="flex items-center gap-3 mb-4">
                <div class="flex items-center justify-center w-8 h-8 rounded-full bg-indigo-100 text-indigo-700 font-bold font-serif">5</div>
                <h3 class="text-2xl font-semibold text-slate-900">Final Conclusion</h3>
            </div>
            
            <p class="explanation-text">
                I have shown that the posterior density factors into the form:
            </p>
            <div class="math-block">
                $$ p(\mu, \sigma^2|y) \propto (\sigma^2)^{-\frac{\nu_n+3}{2}} \exp\left( -\frac{\nu_n\sigma_n^2}{2\sigma^2} \right) \times \exp\left( -\frac{\kappa_n(\mu-\mu_n)^2}{2\sigma^2} \right) $$
            </div>
            <p class="explanation-text">
                This strictly matches the definition of the <strong>Normal-Inverse-\(\chi^2\)</strong> distribution with parameters \((\mu_n, \sigma_n^2/\kappa_n; \nu_n, \sigma_n^2)\). The derivation is complete.
            </p>
        </div>

        <!-- Q.E.D. Summary Box -->
        <div class="bg-slate-900 text-white p-8 rounded-xl shadow-2xl mt-12 relative overflow-hidden">
            <div class="absolute top-0 right-0 -mt-4 -mr-4 w-24 h-24 bg-indigo-500 rounded-full opacity-20 blur-xl"></div>
            
            <h2 class="text-3xl font-serif font-bold mb-6 text-center border-b border-slate-700 pb-4">Solution Summary</h2>
            
            <p class="text-slate-300 text-center mb-8 font-light">The posterior distribution \(p(\mu, \sigma^2|y)\) is \(\text{N-Inv-}\chi^2(\mu_n, \sigma_n^2/\kappa_n; \nu_n, \sigma_n^2)\).</p>
            
            <div class="grid grid-cols-1 md:grid-cols-2 gap-6 text-center">
                <div class="bg-white/10 p-5 rounded-lg backdrop-blur-sm">
                    <div class="text-indigo-300 text-xs uppercase font-bold mb-1">Mean</div>
                    <div class="text-lg">$$ \mu_n = \frac{\kappa_0\mu_0 + n\bar{y}}{\kappa_0 + n} $$</div>
                </div>
                <div class="bg-white/10 p-5 rounded-lg backdrop-blur-sm">
                    <div class="text-indigo-300 text-xs uppercase font-bold mb-1">Precision</div>
                    <div class="text-lg">$$ \kappa_n = \kappa_0 + n $$</div>
                </div>
                <div class="bg-white/10 p-5 rounded-lg backdrop-blur-sm">
                    <div class="text-indigo-300 text-xs uppercase font-bold mb-1">Degrees of Freedom</div>
                    <div class="text-lg">$$ \nu_n = \nu_0 + n $$</div>
                </div>
                <div class="bg-white/10 p-5 rounded-lg backdrop-blur-sm">
                    <div class="text-indigo-300 text-xs uppercase font-bold mb-1">Scale Parameter</div>
                    <div class="text-lg">$$ \sigma_n^2 = \frac{\nu_n\sigma_n^2}{\nu_0 + n} $$</div>
                </div>
            </div>
        </div>

    </div>

    <!-- Script to render KaTeX after DOM Content is loaded -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true}
                ],
                throwOnError : false
            });
        });
    </script>
</body>
</html>